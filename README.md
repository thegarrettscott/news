# News Aggregation API

A FastAPI-based news aggregation and summarization service that provides intelligent briefings on recent news topics using AI-powered research and content extraction.

## ğŸ—ï¸ Architecture Overview

### Core Components

The news system is built around a single FastAPI application (`main.py`) with the following key components:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    News API Layout                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  ğŸ“¡ API Endpoint: GET /news                                 â”‚
â”‚  â”œâ”€â”€ Query Parameters:                                      â”‚
â”‚  â”‚   â”œâ”€â”€ topic (required)                                   â”‚
â”‚  â”‚   â”œâ”€â”€ user (optional - enables async processing)        â”‚
â”‚  â”‚   â”œâ”€â”€ date_range (default: "past 2 days")              â”‚
â”‚  â”‚   â”œâ”€â”€ effort (low/medium/high)                          â”‚
â”‚  â”‚   â”œâ”€â”€ debug (boolean)                                   â”‚
â”‚  â”‚   â”œâ”€â”€ previous_summary (string)                         â”‚
â”‚  â”‚   â”œâ”€â”€ max_steps (1-100, default: 100)                  â”‚
â”‚  â”‚   â””â”€â”€ model (default: "o4-mini")                        â”‚
â”‚  â”‚                                                         â”‚
â”‚  ğŸ”„ Processing Pipeline:                                    â”‚
â”‚  â”œâ”€â”€ 1. News Search (SERP API)                            â”‚
â”‚  â”œâ”€â”€ 2. Content Extraction (Browserless)                  â”‚
â”‚  â”œâ”€â”€ 3. AI Summarization (OpenAI)                         â”‚
â”‚  â”œâ”€â”€ 4. Content Aggregation                               â”‚
â”‚  â””â”€â”€ 5. Response Delivery                                 â”‚
â”‚                                                            â”‚
â”‚  ğŸ”§ Tool Functions:                                        â”‚
â”‚  â”œâ”€â”€ search_news() - Google-style news queries           â”‚
â”‚  â”œâ”€â”€ fetch_content() - Article scraping & extraction     â”‚
â”‚  â”œâ”€â”€ perform_search() - SERP API integration             â”‚
â”‚  â”œâ”€â”€ scrape_content() - Content extraction & parsing     â”‚
â”‚  â””â”€â”€ summarize_article() - AI-powered summarization      â”‚
â”‚                                                            â”‚
â”‚  ğŸ“¤ Output Formats:                                        â”‚
â”‚  â”œâ”€â”€ Synchronous: Direct JSON response                    â”‚
â”‚  â”œâ”€â”€ Asynchronous: Background processing + Bubble API     â”‚
â”‚  â””â”€â”€ Debug Mode: Raw search results                       â”‚
â”‚                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Data Flow Architecture

### 1. Request Processing

```
User Request â†’ API Gateway â†’ Process Handler
                              â”œâ”€â”€ Sync Processing (no user param)
                              â””â”€â”€ Async Processing (with user param)
                                  â”œâ”€â”€ Send 202 Accepted
                                  â”œâ”€â”€ Background Task
                                  â””â”€â”€ Status Updates
```

### 2. News Aggregation Pipeline

```
Topic Input
    â†“
ğŸ” Search Phase (max 10 calls)
    â”œâ”€â”€ search_news(topic, date_range)
    â”œâ”€â”€ SERP API Integration
    â””â”€â”€ Results Filtering (5 per search)
    â†“
ğŸ“„ Content Extraction Phase (3-7 calls)
    â”œâ”€â”€ fetch_content(url)
    â”œâ”€â”€ Browserless Scraping
    â”œâ”€â”€ Readability Processing
    â””â”€â”€ Image Extraction
    â†“
ğŸ¤– AI Processing Phase
    â”œâ”€â”€ Article Summarization (GPT-4.1)
    â”œâ”€â”€ Content Aggregation
    â””â”€â”€ Briefing Generation (o4-mini/others)
    â†“
ğŸ“‹ Output Generation
    â”œâ”€â”€ 10-20 Paragraph Briefing
    â”œâ”€â”€ Structured JSON Response
    â””â”€â”€ Article Metadata
```

## ğŸ”§ Technical Layout

### Core Functions

#### API Endpoint
- **Route**: `GET /news`
- **Handler**: `get_news()` â†’ `process_news_request()`
- **Response Types**: 
  - `200 OK`: Synchronous processing complete
  - `202 Accepted`: Asynchronous processing started
  - `500 Error`: Processing failure

#### Search & Extraction Tools
```python
# News Search Tool
search_news(topic: str, date_range: str)
â”œâ”€â”€ SERP API Integration
â”œâ”€â”€ Query Optimization
â””â”€â”€ Result Limiting (5 articles per search)

# Content Extraction Tool  
fetch_content(url: str)
â”œâ”€â”€ Browserless Scraping
â”œâ”€â”€ Readability Processing
â”œâ”€â”€ Image Detection (OG tags + first img)
â””â”€â”€ Content Summarization
```

#### AI Integration
```python
# Summarization Engine
summarize_article(title: str, text: str)
â”œâ”€â”€ GPT-4.1 Processing
â”œâ”€â”€ 3-sentence summaries
â””â”€â”€ Information density optimization

# Main AI Agent
â”œâ”€â”€ System Prompt: Investigative correspondent
â”œâ”€â”€ Tools: search_news, fetch_content
â”œâ”€â”€ Constraints: 48-hour window, 10 search limit
â””â”€â”€ Output: Structured briefing
```

## ğŸ“± Integration Points

### External APIs
- **SERP API**: Google-style news search
- **Browserless**: Web scraping and content extraction
- **OpenAI**: AI summarization and briefing generation
- **Bubble API**: Status updates and result delivery

### Status Management
```python
# Status Update Flow (Async Mode)
Initial Status â†’ Processing Updates â†’ Completion/Error
     â†“              â†“                    â†“
   "started"    "processing"       "completed"/"error"
   Progress: 0%  Progress: 1-99%   Progress: 100%
```

## ğŸ”„ Response Structure

### Synchronous Response
```json
{
  "summary": "10-20 paragraph briefing with inline links",
  "articles": [
    {
      "url": "https://example.com/article",
      "title": "Article Title",
      "text": "Full article content",
      "image": "https://example.com/image.jpg"
    }
  ]
}
```

### Asynchronous Response (Initial)
```json
{
  "status": "accepted",
  "message": "Request accepted and being processed",
  "user": "user_id",
  "topic": "requested_topic"
}
```

## ğŸš€ Deployment Layout

### Infrastructure
- **Platform**: Fly.io
- **App Name**: `news-8-7pgg`
- **Region**: Dallas (dfw)
- **Scaling**: 2+ machines, auto-start/stop
- **Resources**: 1GB RAM, shared CPU

### Configuration Files
- `fly.toml` - Deployment configuration
- `requirements.txt` - Python dependencies
- `pyproject.toml` - Project metadata
- `Dockerfile` - Container setup

## ğŸ” Environment Variables

```bash
OPENAI_API_KEY=<OpenAI API key>
SERP_API_KEY=<SerpAPI key>
BROWSERLESS_API_KEY=<Browserless token>
```

## ğŸ¯ Key Features

### Content Processing
- **Smart Filtering**: Excludes stories from previous summaries
- **Multi-angle Coverage**: Strategic search planning
- **Rich Extraction**: Title, content, images, metadata
- **AI Summarization**: Concise, fact-focused briefings

### Performance Optimizations
- **Search Limits**: Maximum 10 news searches per request
- **Content Limits**: 3-7 article extractions per request
- **Time Windows**: Strict 48-hour news recency
- **Async Processing**: Background tasks for user requests

### Error Handling
- **Graceful Degradation**: Continues processing on partial failures
- **Status Reporting**: Real-time progress updates
- **Timeout Management**: Maximum step limits
- **API Integration**: Bubble API error reporting

This layout provides a robust, scalable news aggregation system that combines intelligent search, content extraction, and AI-powered summarization into coherent, actionable briefings.